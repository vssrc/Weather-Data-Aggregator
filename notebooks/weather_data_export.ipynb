{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64aa9efc",
   "metadata": {},
   "source": [
    "# Weather API Data Export\n",
    "Configure a location and date span, then export per-day CSV files for each weather API client at the highest available granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a6ad4",
   "metadata": {},
   "source": [
    "Install dependencies if needed (e.g. `pip install pandas requests`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from clients.tomorrow_io_client import TomorrowIOClient, ApiError as TomorrowApiError\n",
    "from clients.open_meteo_client import OpenMeteoClient\n",
    "from clients.visual_crossing_client import VisualCrossingClient\n",
    "from clients.noaa_access_client import NoaaIsdClient, NoaaLcdClient\n",
    "from clients.meteostat_client import MeteostatClient\n",
    "\n",
    "from clients.noaa_access_client import NoaaIsdClient, NoaaLcdClient, ApiError as NoaaAccessApiError\n",
    "from clients.weatherapi_com_client import WeatherApiClient, ApiError as WeatherApiError\n",
    "\n",
    "from clients.openweather_client import OpenWeatherClient, ApiError as OpenWeatherApiError\n",
    "\n",
    "from clients.weatherbit_client import WeatherbitClient, ApiError as WeatherbitApiError\n",
    "\n",
    "from clients.copernicus_cds_client import CopernicusCdsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location and time span configuration\n",
    "CONFIG_PATH = Path('../weather_config.json')\n",
    "CONFIG = json.loads(CONFIG_PATH.read_text())\n",
    "LOCATIONS = CONFIG.get('locations', {})\n",
    "LOCATION_ITEMS = []\n",
    "for key, coords in LOCATIONS.items():\n",
    "    try:\n",
    "        lat = float(coords['lat'])\n",
    "        lon = float(coords['lon'])\n",
    "    except (KeyError, TypeError, ValueError) as exc:\n",
    "        raise ValueError(f\"Invalid coordinates for location '{key}'. Provide numeric 'lat' and 'lon'.\") from exc\n",
    "    LOCATION_ITEMS.append((key, lat, lon))\n",
    "if not LOCATION_ITEMS:\n",
    "    raise ValueError(\"Define at least one location under 'locations' in weather_config.json.\")\n",
    "START_DATE = dt.date(2000, 1, 1)\n",
    "END_DATE = dt.date(2025, 11, 5)\n",
    "# Enable/disable providers\n",
    "USE_TOMORROW_IO = True\n",
    "USE_OPEN_METEO = True\n",
    "USE_VISUAL_CROSSING = True\n",
    "USE_NOAA_ISD = True\n",
    "USE_NOAA_LCD = False\n",
    "USE_OPENWEATHER = True\n",
    "USE_WEATHERBIT = True\n",
    "USE_WEATHERAPI_COM = True\n",
    "USE_COPERNICUS_ERA5_SINGLE = True\n",
    "USE_COPERNICUS_ERA5_LAND = False\n",
    "USE_COPERNICUS_ERA5_PRESSURE = False\n",
    "USE_COPERNICUS_ERA5_LAND_TS = False\n",
    "DATA_ROOT = Path('../data')\n",
    "DATA_ROOT.mkdir(exist_ok=True)\n",
    "UTC = dt.timezone.utc\n",
    "def iter_locations():\n",
    "    for item in LOCATION_ITEMS:\n",
    "        yield item\n",
    "def iter_days(start: dt.date, end: dt.date):\n",
    "    day = start\n",
    "    while day <= end:\n",
    "        yield day\n",
    "        day += dt.timedelta(days=1)\n",
    "DAY_RANGE = list(iter_days(START_DATE, END_DATE))\n",
    "LOCATION_ITEMS, DAY_RANGE[:3], DAY_RANGE[-3:] if DAY_RANGE else []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac219bd2",
   "metadata": {},
   "source": [
    "## Tomorrow.io export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba109a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_TOMORROW_IO:\n",
    "    print('USE_TOMORROW_IO: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        tomorrow_dir = DATA_ROOT / 'tomorrow_io'\n",
    "        tomorrow_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        TOMORROW_FIELDS = [\n",
    "          'temperature', 'temperatureApparent', 'humidity', 'dewPoint', 'pressureSurfaceLevel',\n",
    "          'pressureMeanSeaLevel', 'visibility', 'cloudCover', 'uvIndex', 'windSpeed', 'windGust',\n",
    "          'windDirection', 'precipitationIntensity', 'precipitationProbability', 'precipitationType',\n",
    "          'rainIntensity', 'snowIntensity', 'iceAccumulation', 'solarGHI', 'weatherCode'\n",
    "        ]\n",
    "        TOMORROW_TIMESTEPS = ['5m', '1h']\n",
    "\n",
    "        tomorrow_client = TomorrowIOClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "\n",
    "        def _tomorrow_payload_to_df(payload: dict, day: dt.date) -> pd.DataFrame:\n",
    "            rows = []\n",
    "            for timeline in payload.get('data', {}).get('timelines', []):\n",
    "                timestep = timeline.get('timestep')\n",
    "                for interval in timeline.get('intervals', []):\n",
    "                    values = interval.get('values', {})\n",
    "                    row = {'timestamp': interval.get('startTime'), 'timestep': timestep}\n",
    "                    row.update(values)\n",
    "                    rows.append(row)\n",
    "            if not rows:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(rows)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            return df.sort_values('timestamp')\n",
    "\n",
    "        def _write_tomorrow_results(directory: Path, prefix: str, days, payloads):\n",
    "            for day, payload in zip(days, payloads):\n",
    "                if isinstance(payload, Exception):\n",
    "                    print(f'{prefix}: request failed for {day}: {payload}')\n",
    "                    continue\n",
    "                try:\n",
    "                    df_day = _tomorrow_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f'{prefix}: no data for {day}')\n",
    "                        continue\n",
    "                    output_path = directory / f'{day.isoformat()}.csv'\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f'{prefix}: wrote {output_path}')\n",
    "                except Exception as exc:\n",
    "                    print(f\"{prefix}: unexpected error for {day}: {exc}\")\n",
    "\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'Tomorrow.io[{location_key}]'\n",
    "            location_dir = tomorrow_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            historical_days = []\n",
    "            historical_requests = []\n",
    "            forecast_days = []\n",
    "            forecast_requests = []\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                if day < today - dt.timedelta(days=1):\n",
    "                    print(f'{prefix}: skipping {day} (plan permits only last 24 hours).')\n",
    "                    continue\n",
    "\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    print(f'{prefix}: skipping {day} (already exported).')\n",
    "                    continue\n",
    "\n",
    "                start = dt.datetime.combine(day, dt.time(0, 0), tzinfo=UTC)\n",
    "                end = start + dt.timedelta(days=1)\n",
    "\n",
    "                request = {\n",
    "                    'location': (lat, lon),\n",
    "                    'start_time': start,\n",
    "                    'end_time': end,\n",
    "                    'fields': TOMORROW_FIELDS,\n",
    "                    'timesteps': TOMORROW_TIMESTEPS,\n",
    "                    'timezone': 'UTC',\n",
    "                }\n",
    "\n",
    "                if day < today:\n",
    "                    historical_days.append(day)\n",
    "                    historical_requests.append(dict(request))\n",
    "                else:\n",
    "                    forecast_days.append(day)\n",
    "                    forecast_requests.append(dict(request))\n",
    "\n",
    "            historical_payloads = tomorrow_client.get_historical_batch(historical_requests)\n",
    "            forecast_payloads = tomorrow_client.get_forecast_batch(forecast_requests)\n",
    "\n",
    "            _write_tomorrow_results(location_dir, prefix, historical_days, historical_payloads)\n",
    "            _write_tomorrow_results(location_dir, prefix, forecast_days, forecast_payloads)\n",
    "    except Exception as exc:\n",
    "        print(f\"Tomorrow.io: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d01010",
   "metadata": {},
   "source": [
    "## Open-Meteo export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_OPEN_METEO:\n",
    "    print('USE_OPEN_METEO: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        open_meteo_dir = DATA_ROOT / 'open_meteo'\n",
    "        open_meteo_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        OPEN_METEO_HOURLY = [\n",
    "          'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature',\n",
    "          'pressure_msl', 'surface_pressure', 'cloud_cover', 'cloud_cover_low', 'cloud_cover_mid',\n",
    "          'cloud_cover_high', 'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m',\n",
    "          'shortwave_radiation', 'direct_radiation', 'diffuse_radiation', 'global_tilted_irradiance',\n",
    "          'sunshine_duration', 'precipitation', 'rain', 'snowfall', 'weather_code',\n",
    "          'soil_temperature_0cm', 'soil_moisture_0_1cm'\n",
    "        ]\n",
    "\n",
    "        open_meteo_client = OpenMeteoClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "\n",
    "        def _open_meteo_payload_to_df(payload: dict, day: dt.date) -> pd.DataFrame:\n",
    "            hourly = payload.get('hourly', {})\n",
    "            if not hourly:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(hourly)\n",
    "            if 'time' not in df:\n",
    "                return pd.DataFrame()\n",
    "            df.rename(columns={'time': 'timestamp'}, inplace=True)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            return df.sort_values('timestamp')\n",
    "\n",
    "        def _write_open_meteo_results(directory: Path, prefix: str, days, payloads):\n",
    "            for day, payload in zip(days, payloads):\n",
    "                if isinstance(payload, Exception):\n",
    "                    print(f'{prefix}: request failed for {day}: {payload}')\n",
    "                    continue\n",
    "                try:\n",
    "                    df_day = _open_meteo_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f'{prefix}: no data for {day}')\n",
    "                        continue\n",
    "                    output_path = directory / f'{day.isoformat()}.csv'\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f'{prefix}: wrote {output_path}')\n",
    "                except Exception as exc:\n",
    "                    print(f\"{prefix}: unexpected error for {day}: {exc}\")\n",
    "\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'Open-Meteo[{location_key}]'\n",
    "            location_dir = open_meteo_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            historical_days = []\n",
    "            historical_requests = []\n",
    "            forecast_days = []\n",
    "            forecast_requests = []\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    print(f'{prefix}: skipping {day} (already exported).')\n",
    "                    continue\n",
    "\n",
    "                request = {\n",
    "                    'location': (lat, lon),\n",
    "                    'start_date': day,\n",
    "                    'end_date': day,\n",
    "                    'hourly': OPEN_METEO_HOURLY,\n",
    "                    'timezone': 'UTC',\n",
    "                }\n",
    "                if day < today:\n",
    "                    historical_days.append(day)\n",
    "                    historical_requests.append(dict(request))\n",
    "                else:\n",
    "                    forecast_days.append(day)\n",
    "                    forecast_requests.append(dict(request))\n",
    "\n",
    "            historical_payloads = open_meteo_client.get_historical_batch(historical_requests)\n",
    "            forecast_payloads = open_meteo_client.get_forecast_batch(forecast_requests)\n",
    "\n",
    "            _write_open_meteo_results(location_dir, prefix, historical_days, historical_payloads)\n",
    "            _write_open_meteo_results(location_dir, prefix, forecast_days, forecast_payloads)\n",
    "    except Exception as exc:\n",
    "        print(f\"Open-Meteo: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b0083",
   "metadata": {},
   "source": [
    "## Visual Crossing export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_VISUAL_CROSSING:\n",
    "    print('USE_VISUAL_CROSSING: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        visual_crossing_dir = DATA_ROOT / 'visual_crossing'\n",
    "        visual_crossing_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        visual_crossing_client = VisualCrossingClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "        max_forecast_day = today + dt.timedelta(days=15)\n",
    "\n",
    "        def _visual_crossing_payload_to_df(payload: dict, day: dt.date) -> pd.DataFrame:\n",
    "            hours = []\n",
    "            for daily in payload.get('days', []):\n",
    "                day_date = daily.get('datetime')\n",
    "                for entry in daily.get('hours', []):\n",
    "                    row = dict(entry)\n",
    "                    row['parent_day'] = day_date\n",
    "                    epoch = entry.get('datetimeEpoch')\n",
    "                    if epoch is not None:\n",
    "                        row['timestamp'] = pd.to_datetime(epoch, unit='s', utc=True)\n",
    "                    elif entry.get('datetime') is not None and day_date is not None:\n",
    "                        row['timestamp'] = pd.to_datetime(f\"{day_date}T{entry['datetime']}\")\n",
    "                    hours.append(row)\n",
    "            if not hours:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(hours)\n",
    "            if 'timestamp' not in df:\n",
    "                return pd.DataFrame()\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            return df.sort_values('timestamp')\n",
    "\n",
    "        def _write_visual_crossing_results(directory: Path, prefix: str, days, payloads):\n",
    "            for day, payload in zip(days, payloads):\n",
    "                if isinstance(payload, Exception):\n",
    "                    print(f'{prefix}: request failed for {day}: {payload}')\n",
    "                    continue\n",
    "                try:\n",
    "                    df_day = _visual_crossing_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f'{prefix}: no data for {day}')\n",
    "                        continue\n",
    "                    output_path = directory / f'{day.isoformat()}.csv'\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f'{prefix}: wrote {output_path}')\n",
    "                except Exception as exc:\n",
    "                    print(f\"{prefix}: unexpected error for {day}: {exc}\")\n",
    "\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'Visual Crossing[{location_key}]'\n",
    "            location_dir = visual_crossing_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            historical_days = []\n",
    "            historical_requests = []\n",
    "            forecast_days = []\n",
    "            forecast_requests = []\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                if day > max_forecast_day:\n",
    "                    print(f'{prefix}: skipping {day} (beyond forecast horizon).')\n",
    "                    continue\n",
    "\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    print(f'{prefix}: skipping {day} (already exported).')\n",
    "                    continue\n",
    "\n",
    "                start = day\n",
    "                end = day + dt.timedelta(days=1)\n",
    "\n",
    "                request = {\n",
    "                    'location': f'{lat},{lon}',\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'include': ['hours'],\n",
    "                    'unit_group': 'metric',\n",
    "                }\n",
    "\n",
    "                if day < today:\n",
    "                    historical_days.append(day)\n",
    "                    historical_requests.append(dict(request))\n",
    "                else:\n",
    "                    forecast_days.append(day)\n",
    "                    forecast_requests.append(dict(request))\n",
    "\n",
    "            historical_payloads = visual_crossing_client.get_historical_batch(historical_requests)\n",
    "            forecast_payloads = visual_crossing_client.get_forecast_batch(forecast_requests)\n",
    "\n",
    "            _write_visual_crossing_results(location_dir, prefix, historical_days, historical_payloads)\n",
    "            _write_visual_crossing_results(location_dir, prefix, forecast_days, forecast_payloads)\n",
    "    except Exception as exc:\n",
    "        print(f\"Visual Crossing: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ff992",
   "metadata": {},
   "source": [
    "## NOAA ISD export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd580c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not USE_NOAA_ISD:\n",
    "    print('USE_NOAA_ISD: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        noaa_isd_dir = DATA_ROOT / 'noaa_isd'\n",
    "        noaa_isd_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        noaa_isd_client = NoaaIsdClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "\n",
    "        def _parse_isd_temp(value):\n",
    "            if not value or value in {'+9999,9', '-9999,9'}:\n",
    "                return None\n",
    "            token = value.strip()\n",
    "            if not token:\n",
    "                return None\n",
    "            sign = -1 if token.startswith('-') else 1\n",
    "            digits = ''.join(ch for ch in token if ch.isdigit())\n",
    "            if not digits:\n",
    "                return None\n",
    "            try:\n",
    "                numeric = int(digits[:4])\n",
    "            except ValueError:\n",
    "                return None\n",
    "            return sign * numeric / 10.0\n",
    "\n",
    "        def _noaa_isd_payload_to_df(payload: list[dict], day: dt.date) -> pd.DataFrame:\n",
    "            if not payload:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(payload)\n",
    "            if 'DATE' not in df:\n",
    "                return pd.DataFrame()\n",
    "            df['timestamp'] = pd.to_datetime(df['DATE'], errors='coerce')\n",
    "            df = df.dropna(subset=['timestamp'])\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            if df.empty:\n",
    "                return df\n",
    "            df = df.sort_values('timestamp')\n",
    "            if 'TMP' in df.columns:\n",
    "                df['temperature_c'] = df['TMP'].apply(_parse_isd_temp)\n",
    "            if 'DEW' in df.columns:\n",
    "                df['dewpoint_c'] = df['DEW'].apply(_parse_isd_temp)\n",
    "            return df\n",
    "\n",
    "        for location_key, *_coords in iter_locations():\n",
    "            station_id = LOCATIONS.get(location_key, {}).get('noaaIsdStation')\n",
    "            if not station_id:\n",
    "                print(f\"{location_key}: missing 'noaaIsdStation'; skipping.\")\n",
    "                continue\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                if day > today:\n",
    "                    continue\n",
    "                output_path = noaa_isd_dir / location_key / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    continue\n",
    "                output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                start = dt.datetime.combine(day, dt.time(0, 0), tzinfo=UTC)\n",
    "                end = start + dt.timedelta(days=1)\n",
    "                payload = noaa_isd_client.get_observations(\n",
    "                    station_id=station_id,\n",
    "                    start_time=start,\n",
    "                    end_time=end,\n",
    "                )\n",
    "                try:\n",
    "                    df_day = _noaa_isd_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f\"{location_key}: no ISD data for {day}\")\n",
    "                        continue\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f\"{location_key}: wrote {output_path}\")\n",
    "                except Exception as exc:  # noqa: BLE001\n",
    "                    print(f\"{location_key}: unexpected ISD error for {day}: {exc}\")\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"NOAA ISD: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5814a6",
   "metadata": {},
   "source": [
    "## NOAA LCD export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not USE_NOAA_LCD:\n",
    "    print('USE_NOAA_LCD: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        noaa_lcd_dir = DATA_ROOT / 'noaa_lcd'\n",
    "        noaa_lcd_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        noaa_lcd_client = NoaaLcdClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "\n",
    "        def _fahrenheit_to_celsius(value):\n",
    "            if value is None or (isinstance(value, str) and not value.strip()):\n",
    "                return None\n",
    "            try:\n",
    "                numeric = float(value)\n",
    "            except ValueError:\n",
    "                return None\n",
    "            return (numeric - 32.0) * 5.0 / 9.0\n",
    "\n",
    "        def _noaa_lcd_payload_to_df(payload: list[dict], day: dt.date) -> pd.DataFrame:\n",
    "            if not payload:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(payload)\n",
    "            if 'DATE' not in df:\n",
    "                return pd.DataFrame()\n",
    "            df['timestamp'] = pd.to_datetime(df['DATE'], errors='coerce')\n",
    "            df = df.dropna(subset=['timestamp'])\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            if df.empty:\n",
    "                return df\n",
    "            df = df.sort_values('timestamp')\n",
    "            if 'HourlyDryBulbTemperature' in df.columns:\n",
    "                df['dry_bulb_f'] = pd.to_numeric(df['HourlyDryBulbTemperature'], errors='coerce')\n",
    "                df['dry_bulb_c'] = df['dry_bulb_f'].apply(_fahrenheit_to_celsius)\n",
    "            if 'HourlyDewPointTemperature' in df.columns:\n",
    "                df['dewpoint_f'] = pd.to_numeric(df['HourlyDewPointTemperature'], errors='coerce')\n",
    "                df['dewpoint_c'] = df['dewpoint_f'].apply(_fahrenheit_to_celsius)\n",
    "            return df\n",
    "\n",
    "        for location_key, *_coords in iter_locations():\n",
    "            station_id = LOCATIONS.get(location_key, {}).get('noaaLcdStation')\n",
    "            if not station_id:\n",
    "                print(f\"{location_key}: missing 'noaaLcdStation'; skipping.\")\n",
    "                continue\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                if day > today:\n",
    "                    continue\n",
    "                output_path = noaa_lcd_dir / location_key / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    continue\n",
    "                output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                start = dt.datetime.combine(day, dt.time(0, 0), tzinfo=UTC)\n",
    "                end = start + dt.timedelta(days=1)\n",
    "                payload = noaa_lcd_client.get_observations(\n",
    "                    station_id=station_id,\n",
    "                    start_time=start,\n",
    "                    end_time=end,\n",
    "                )\n",
    "                try:\n",
    "                    df_day = _noaa_lcd_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f\"{location_key}: no LCD data for {day}\")\n",
    "                        continue\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f\"{location_key}: wrote {output_path}\")\n",
    "                except Exception as exc:  # noqa: BLE001\n",
    "                    print(f\"{location_key}: unexpected LCD error for {day}: {exc}\")\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"NOAA LCD: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f5c01",
   "metadata": {},
   "source": [
    "## Meteostat export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_METEOSTAT:\n",
    "    print('USE_METEOSTAT: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        meteostat_dir = DATA_ROOT / 'meteostat'\n",
    "        meteostat_dir.mkdir(parents=True, exist_ok=True)\n",
    "        meteostat_client = MeteostatClient(config_path='../weather_config.json')\n",
    "        def _meteostat_payload_to_df(payload, day):\n",
    "            if not payload:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(payload)\n",
    "            if 'timestamp' not in df.columns:\n",
    "                if 'time' in df.columns:\n",
    "                    df['timestamp'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "                else:\n",
    "                    return pd.DataFrame()\n",
    "            else:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "            df = df.dropna(subset=['timestamp'])\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            return df.sort_values('timestamp')\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'Meteostat[{location_key}]'\n",
    "            location_dir = meteostat_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for day in DAY_RANGE:\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != dt.date.today() and output_path.exists():\n",
    "                    continue\n",
    "                start = dt.datetime.combine(day, dt.time(0, 0))\n",
    "                end = start + dt.timedelta(days=1)\n",
    "                payload = meteostat_client.get_hourly(\n",
    "                    location=(lat, lon),\n",
    "                    start_time=start,\n",
    "                    end_time=end,\n",
    "                )\n",
    "                try:\n",
    "                    df_day = _meteostat_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f\"{prefix}: no Meteostat data for {day}\")\n",
    "                        continue\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f\"{prefix}: wrote {output_path}\")\n",
    "                except Exception as exc:  # noqa: BLE001\n",
    "                    print(f\"{prefix}: unexpected Meteostat error for {day}: {exc}\")\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"Meteostat: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c27d83",
   "metadata": {},
   "source": [
    "## NASA POWER export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_NASA_POWER:\n",
    "    print('USE_NASA_POWER: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        nasa_power_dir = DATA_ROOT / 'nasa_power'\n",
    "        nasa_power_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        nasa_power_client = NasaPowerClient(config_path='../weather_config.json')\n",
    "\n",
    "        def _nasa_power_payload_to_df(payload, day):\n",
    "            props = payload.get('properties', {}) if isinstance(payload, dict) else {}\n",
    "            parameters = props.get('parameter', {})\n",
    "            if not parameters:\n",
    "                return pd.DataFrame()\n",
    "            rows = {}\n",
    "            for param, series in parameters.items():\n",
    "                if not isinstance(series, dict):\n",
    "                    continue\n",
    "                for stamp, value in series.items():\n",
    "                    rows.setdefault(stamp, {})[param] = value\n",
    "            records = []\n",
    "            for stamp, values in rows.items():\n",
    "                try:\n",
    "                    timestamp = dt.datetime.strptime(str(stamp), '%Y%m%d%H').replace(tzinfo=dt.timezone.utc)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                if timestamp.date() != day:\n",
    "                    continue\n",
    "                record = dict(values)\n",
    "                record['timestamp'] = timestamp\n",
    "                records.append(record)\n",
    "            if not records:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(records).sort_values('timestamp')\n",
    "            rename_map = {\n",
    "                'T2M': 'temperature_c',\n",
    "                'T2MDEW': 'dewpoint_c',\n",
    "                'RH2M': 'rel_humidity_pct',\n",
    "                'WS10M': 'wind_speed_10m_m_s',\n",
    "                'WD10M': 'wind_dir_10m_deg',\n",
    "                'PRECTOTCORR': 'precip_mm_hr',\n",
    "                'PS': 'surface_pressure_kpa',\n",
    "            }\n",
    "            df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns}, inplace=True)\n",
    "            return df\n",
    "\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'NASA POWER[{location_key}]'\n",
    "            location_dir = nasa_power_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != dt.date.today() and output_path.exists():\n",
    "                    continue\n",
    "                payload = nasa_power_client.get_hourly(\n",
    "                    location=(lat, lon),\n",
    "                    start_time=day,\n",
    "                    end_time=day,\n",
    "                )\n",
    "                try:\n",
    "                    df_day = _nasa_power_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f\"{prefix}: no data for {day}\")\n",
    "                        continue\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f\"{prefix}: wrote {output_path}\")\n",
    "                except Exception as exc:  # noqa: BLE001\n",
    "                    print(f\"{prefix}: unexpected NASA POWER error for {day}: {exc}\")\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"NASA POWER: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304647f0",
   "metadata": {},
   "source": [
    "## IEM ASOS export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_IEM_ASOS:\n",
    "    print('USE_IEM_ASOS: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        iem_dir = DATA_ROOT / 'iem_asos'\n",
    "        iem_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        iem_client = IemAsosClient(config_path='../weather_config.json')\n",
    "\n",
    "        def _iem_payload_to_df(payload, day):\n",
    "            if payload is None or payload.empty:\n",
    "                return pd.DataFrame()\n",
    "            df = payload.copy()\n",
    "            if 'timestamp' not in df.columns:\n",
    "                valid_col = next((col for col in df.columns if col.lower().startswith('valid')), None)\n",
    "                if valid_col:\n",
    "                    df['timestamp'] = pd.to_datetime(df[valid_col], utc=True, errors='coerce')\n",
    "            df = df.dropna(subset=['timestamp'])\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            if df.empty:\n",
    "                return df\n",
    "            df = df.sort_values('timestamp')\n",
    "            rename_map = {\n",
    "                'tmpf': 'temperature_f',\n",
    "                'dwpf': 'dewpoint_f',\n",
    "                'sknt': 'wind_speed_knots',\n",
    "                'drct': 'wind_dir_deg',\n",
    "                'gust_sknt': 'wind_gust_knots',\n",
    "                'precip': 'precip_in',\n",
    "                'pres1': 'station_pressure_inhg',\n",
    "            }\n",
    "            df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "            if 'temperature_f' in df.columns:\n",
    "                df['temperature_c'] = (df['temperature_f'] - 32.0) * 5.0 / 9.0\n",
    "            if 'dewpoint_f' in df.columns:\n",
    "                df['dewpoint_c'] = (df['dewpoint_f'] - 32.0) * 5.0 / 9.0\n",
    "            if 'wind_speed_knots' in df.columns:\n",
    "                df['wind_speed_mps'] = df['wind_speed_knots'] * 0.514444\n",
    "            if 'wind_gust_knots' in df.columns:\n",
    "                df['wind_gust_mps'] = df['wind_gust_knots'] * 0.514444\n",
    "            if 'precip_in' in df.columns:\n",
    "                df['precip_mm'] = df['precip_in'] * 25.4\n",
    "            return df\n",
    "\n",
    "        for location_key, *_coords in iter_locations():\n",
    "            station = LOCATIONS.get(location_key, {}).get('iemStation')\n",
    "            network = LOCATIONS.get(location_key, {}).get('iemNetwork')\n",
    "            if not station or not network:\n",
    "                print(f\"{location_key}: missing IEM metadata; skipping.\")\n",
    "                continue\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                output_path = iem_dir / location_key / f'{day.isoformat()}.csv'\n",
    "                if day != dt.date.today() and output_path.exists():\n",
    "                    continue\n",
    "                output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                start = dt.datetime.combine(day, dt.time(0, 0))\n",
    "                end = start + dt.timedelta(days=1)\n",
    "                payload = iem_client.get_observations(\n",
    "                    station=station,\n",
    "                    network=network,\n",
    "                    start_time=start,\n",
    "                    end_time=end,\n",
    "                )\n",
    "                try:\n",
    "                    df_day = _iem_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f\"{station}: no IEM ASOS data for {day}\")\n",
    "                        continue\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f\"{station}: wrote {output_path}\")\n",
    "                except Exception as exc:\n",
    "                    print(f\"{station}: unexpected IEM error for {day}: {exc}\")\n",
    "    except Exception as exc:\n",
    "        print(f\"IEM ASOS: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6dd6f8",
   "metadata": {},
   "source": [
    "## Copernicus ERA5 exports\n",
    "The exporter now treats each ERA5 dataset (single levels, ERA5-Land, ERA5 pressure levels, and ERA5-Land time-series) as a standalone provider. Enable any combination via the corresponding `USE_COPERNICUS_*` flags before running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d89d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "COPERNICUS_EXPORTS = [\n",
    "    {\n",
    "        \"label\": \"ERA5 single levels\",\n",
    "        \"provider\": \"copernicus_era5_single\",\n",
    "        \"dir_name\": \"copernicus_era5_single\",\n",
    "        \"area_attr\": \"copernicusEra5Area\",\n",
    "        \"enabled\": USE_COPERNICUS_ERA5_SINGLE,\n",
    "        \"variant\": \"single\",\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ERA5-Land\",\n",
    "        \"provider\": \"copernicus_era5_land\",\n",
    "        \"dir_name\": \"copernicus_era5_land\",\n",
    "        \"area_attr\": \"copernicusEra5LandArea\",\n",
    "        \"enabled\": USE_COPERNICUS_ERA5_LAND,\n",
    "        \"variant\": \"land\",\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ERA5 pressure levels\",\n",
    "        \"provider\": \"copernicus_era5_pressure\",\n",
    "        \"dir_name\": \"copernicus_era5_pressure\",\n",
    "        \"area_attr\": \"copernicusEra5Area\",\n",
    "        \"enabled\": USE_COPERNICUS_ERA5_PRESSURE,\n",
    "        \"variant\": \"pressure\",\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ERA5-Land time-series\",\n",
    "        \"provider\": \"copernicus_era5_land_timeseries\",\n",
    "        \"dir_name\": \"copernicus_era5_land_timeseries\",\n",
    "        \"area_attr\": None,\n",
    "        \"enabled\": USE_COPERNICUS_ERA5_LAND_TS,\n",
    "        \"variant\": \"land_ts\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def _filter_day_df(payload, day):\n",
    "    if payload is None or payload.empty:\n",
    "        return pd.DataFrame()\n",
    "    df = payload.copy()\n",
    "    if 'timestamp' not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    df = df[df['timestamp'].dt.date == day]\n",
    "    if df.empty:\n",
    "        return df\n",
    "    return df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _transform_payload(df, variant):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    if variant in ('single', 'land', 'land_ts') and 't2m' in df.columns:\n",
    "        df['temperature_c'] = df['t2m'] - 273.15\n",
    "    if variant in ('single', 'land', 'land_ts') and 'tp' in df.columns:\n",
    "        df['precip_mm'] = df['tp'] * 1000.0\n",
    "    if variant in ('single', 'land_ts') and 'u10' in df.columns:\n",
    "        df['wind_u10_mps'] = df['u10']\n",
    "    if variant in ('single', 'land_ts') and 'v10' in df.columns:\n",
    "        df['wind_v10_mps'] = df['v10']\n",
    "    if variant == 'pressure' and 'temperature' in df.columns:\n",
    "        df['temperature_c'] = df['temperature'] - 273.15\n",
    "    return df\n",
    "\n",
    "for cfg in COPERNICUS_EXPORTS:\n",
    "    if not cfg['enabled']:\n",
    "        print(f\"{cfg['label']}: disabled, skipping export block.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\n",
    "=== {cfg['label']} ===\")\n",
    "    provider_dir = DATA_ROOT / cfg['dir_name']\n",
    "    provider_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        client = CopernicusCdsClient(config_path='../weather_config.json', provider=cfg['provider'])\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"{cfg['label']}: client init failed -> {exc}\")\n",
    "        continue\n",
    "\n",
    "    for location_key, lat, lon in iter_locations():\n",
    "        extras = LOCATIONS.get(location_key, {})\n",
    "        area_attr = cfg.get('area_attr')\n",
    "        area = extras.get(area_attr) if area_attr else None\n",
    "        if area_attr and not area:\n",
    "            print(f\"{cfg['label']} -> {location_key}: missing {area_attr}; skipping location.\")\n",
    "            continue\n",
    "\n",
    "        for day in DAY_RANGE:\n",
    "            output_path = provider_dir / location_key / f'{day.isoformat()}.csv'\n",
    "            if day != dt.date.today() and output_path.exists():\n",
    "                continue\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            try:\n",
    "                payload = client.get_dataset(\n",
    "                    area=area,\n",
    "                    start_date=day,\n",
    "                    end_date=day,\n",
    "                    latitude=lat,\n",
    "                    longitude=lon,\n",
    "                )\n",
    "                df_day = _transform_payload(_filter_day_df(payload, day), cfg['variant'])\n",
    "                if df_day.empty:\n",
    "                    print(f\"{cfg['label']} -> {location_key}: no data for {day}\")\n",
    "                    continue\n",
    "                df_day.to_csv(output_path, index=False)\n",
    "                print(f\"{cfg['label']} -> {location_key}: wrote {output_path}\")\n",
    "            except Exception as exc:  # noqa: BLE001\n",
    "                print(f\"{cfg['label']} -> {location_key}: error on {day}: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b910dc",
   "metadata": {},
   "source": [
    "## OpenWeather export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5abb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_OPENWEATHER:\n",
    "    print('USE_OPENWEATHER: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        openweather_dir = DATA_ROOT / 'openweather'\n",
    "        openweather_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        openweather_client = OpenWeatherClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "        now_utc = dt.datetime.now(dt.timezone.utc)\n",
    "\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'OpenWeather[{location_key}]'\n",
    "            location_dir = openweather_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            request_days = []\n",
    "            request_payloads = []\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                if day > today:\n",
    "                    print(f'{prefix}: skipping {day} (future dates unsupported).')\n",
    "                    continue\n",
    "\n",
    "                start = dt.datetime.combine(day, dt.time(0, 0), tzinfo=UTC)\n",
    "                end = min(start + dt.timedelta(days=1), now_utc)\n",
    "                if end <= start:\n",
    "                    print(f'{prefix}: skipping {day} (no elapsed time yet).')\n",
    "                    continue\n",
    "\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    print(f'{prefix}: skipping {day} (already exported).')\n",
    "                    continue\n",
    "\n",
    "                request_payloads.append({\n",
    "                    'location': (lat, lon),\n",
    "                    'start_time': start,\n",
    "                    'end_time': end,\n",
    "                    'interval_type': 'hour',\n",
    "                    'units': 'metric',\n",
    "                })\n",
    "                request_days.append(day)\n",
    "\n",
    "            payloads = openweather_client.get_historical_batch(request_payloads)\n",
    "\n",
    "            for day, payload in zip(request_days, payloads):\n",
    "                if isinstance(payload, Exception):\n",
    "                    print(f'{prefix}: request failed for {day}: {payload}')\n",
    "                    continue\n",
    "                try:\n",
    "                    records = payload.get('list', [])\n",
    "                    if not records:\n",
    "                        print(f'{prefix}: no data for {day}')\n",
    "                        continue\n",
    "\n",
    "                    df = pd.json_normalize(records)\n",
    "                    if 'dt' in df.columns:\n",
    "                        df['timestamp'] = pd.to_datetime(df['dt'], unit='s', utc=True)\n",
    "                    elif 'time' in df.columns:\n",
    "                        df['timestamp'] = pd.to_datetime(df['time'], utc=True)\n",
    "                    else:\n",
    "                        print(f'{prefix}: unable to determine timestamp for {day}')\n",
    "                        continue\n",
    "\n",
    "                    df = df[df['timestamp'].dt.date == day]\n",
    "                    if df.empty:\n",
    "                        print(f'{prefix}: no data for {day}')\n",
    "                        continue\n",
    "\n",
    "                    output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                    df.to_csv(output_path, index=False)\n",
    "                    print(f'{prefix}: wrote {output_path}')\n",
    "                except Exception as exc:\n",
    "                    print(f'{prefix}: unexpected error for {day}: {exc}')\n",
    "    except Exception as exc:\n",
    "        print(f'OpenWeather: unexpected error: {exc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff39df7",
   "metadata": {},
   "source": [
    "## Weatherbit export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99334a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_WEATHERBIT:\n",
    "    print('USE_WEATHERBIT: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        weatherbit_dir = DATA_ROOT / 'weatherbit'\n",
    "        weatherbit_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        weatherbit_client = WeatherbitClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "\n",
    "        def _weatherbit_payload_to_df(payload: dict, day: dt.date) -> pd.DataFrame:\n",
    "            data = payload.get('data', [])\n",
    "            if not data:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(data)\n",
    "            if 'timestamp_utc' in df.columns:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp_utc'], utc=True)\n",
    "            elif 'ts' in df.columns:\n",
    "                df['timestamp'] = pd.to_datetime(df['ts'], unit='s', utc=True)\n",
    "            else:\n",
    "                df['timestamp'] = pd.to_datetime(df.get('datetime', pd.Series(dtype=str)), utc=True, errors='coerce')\n",
    "            df = df.dropna(subset=['timestamp'])\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            return df.sort_values('timestamp')\n",
    "\n",
    "        def _write_weatherbit_results(directory: Path, prefix: str, days, payloads):\n",
    "            for day, payload in zip(days, payloads):\n",
    "                if isinstance(payload, Exception):\n",
    "                    print(f'{prefix}: request failed for {day}: {payload}')\n",
    "                    continue\n",
    "                try:\n",
    "                    df_day = _weatherbit_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f'{prefix}: no data for {day}')\n",
    "                        continue\n",
    "                    output_path = directory / f'{day.isoformat()}.csv'\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f'{prefix}: wrote {output_path}')\n",
    "                except Exception as exc:\n",
    "                    print(f\"{prefix}: unexpected error for {day}: {exc}\")\n",
    "\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'Weatherbit[{location_key}]'\n",
    "            location_dir = weatherbit_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            historical_days = []\n",
    "            historical_requests = []\n",
    "            forecast_days = []\n",
    "            forecast_requests = []\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    print(f'{prefix}: skipping {day} (already exported).')\n",
    "                    continue\n",
    "\n",
    "                start = dt.datetime.combine(day, dt.time(0, 0), tzinfo=UTC)\n",
    "                end = start + dt.timedelta(days=1)\n",
    "                if day < today:\n",
    "                    historical_days.append(day)\n",
    "                    historical_requests.append({\n",
    "                        'location': (lat, lon),\n",
    "                        'start_time': start,\n",
    "                        'end_time': end,\n",
    "                        'units': 'M',\n",
    "                    })\n",
    "                else:\n",
    "                    forecast_days.append(day)\n",
    "                    forecast_requests.append({\n",
    "                        'location': (lat, lon),\n",
    "                        'hours': 48,\n",
    "                        'units': 'M',\n",
    "                    })\n",
    "\n",
    "            historical_payloads = weatherbit_client.get_historical_batch(historical_requests)\n",
    "            forecast_payloads = weatherbit_client.get_forecast_batch(forecast_requests)\n",
    "\n",
    "            _write_weatherbit_results(location_dir, prefix, historical_days, historical_payloads)\n",
    "            _write_weatherbit_results(location_dir, prefix, forecast_days, forecast_payloads)\n",
    "    except Exception as exc:\n",
    "        print(f\"Weatherbit: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78dbf7",
   "metadata": {},
   "source": [
    "## WeatherAPI.com export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_WEATHERAPI_COM:\n",
    "    print('USE_WEATHERAPI_COM: disabled, skipping export.')\n",
    "else:\n",
    "    try:\n",
    "        weatherapi_dir = DATA_ROOT / 'weatherapi_com'\n",
    "        weatherapi_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        weatherapi_client = WeatherApiClient(config_path='../weather_config.json')\n",
    "        today = dt.date.today()\n",
    "        forecast_horizon = today + dt.timedelta(days=14)\n",
    "\n",
    "        def _weatherapi_rows(block: dict) -> list:\n",
    "            rows = []\n",
    "            for hour in block.get('hour', []):\n",
    "                row = dict(hour)\n",
    "                if 'time_epoch' in hour:\n",
    "                    row['timestamp'] = pd.to_datetime(hour['time_epoch'], unit='s', utc=True)\n",
    "                elif 'time' in hour:\n",
    "                    row['timestamp'] = pd.to_datetime(hour['time'], utc=True)\n",
    "                row['forecast_date'] = block.get('date')\n",
    "                rows.append(row)\n",
    "            return rows\n",
    "\n",
    "        def _weatherapi_payload_to_df(payload: dict, day: dt.date) -> pd.DataFrame:\n",
    "            forecast = payload.get('forecast', {})\n",
    "            forecast_days = forecast.get('forecastday', [])\n",
    "            rows = []\n",
    "            for block in forecast_days:\n",
    "                rows.extend(_weatherapi_rows(block))\n",
    "            if not rows:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(rows)\n",
    "            if 'timestamp' not in df:\n",
    "                if 'time_epoch' in df.columns:\n",
    "                    df['timestamp'] = pd.to_datetime(df['time_epoch'], unit='s', utc=True)\n",
    "                elif 'time' in df.columns:\n",
    "                    df['timestamp'] = pd.to_datetime(df['time'], utc=True)\n",
    "                else:\n",
    "                    return pd.DataFrame()\n",
    "            df = df[df['timestamp'].dt.date == day]\n",
    "            return df.sort_values('timestamp')\n",
    "\n",
    "        def _write_weatherapi_results(directory: Path, prefix: str, days, payloads):\n",
    "            for day, payload in zip(days, payloads):\n",
    "                if isinstance(payload, Exception):\n",
    "                    print(f'{prefix}: request failed for {day}: {payload}')\n",
    "                    continue\n",
    "                try:\n",
    "                    df_day = _weatherapi_payload_to_df(payload, day)\n",
    "                    if df_day.empty:\n",
    "                        print(f'{prefix}: no data for {day}')\n",
    "                        continue\n",
    "                    output_path = directory / f'{day.isoformat()}.csv'\n",
    "                    df_day.to_csv(output_path, index=False)\n",
    "                    print(f'{prefix}: wrote {output_path}')\n",
    "                except Exception as exc:\n",
    "                    print(f\"{prefix}: unexpected error for {day}: {exc}\")\n",
    "\n",
    "        for location_key, lat, lon in iter_locations():\n",
    "            prefix = f'WeatherAPI.com[{location_key}]'\n",
    "            location_dir = weatherapi_dir / location_key\n",
    "            location_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            historical_days = []\n",
    "            historical_requests = []\n",
    "            forecast_days = []\n",
    "            forecast_requests = []\n",
    "\n",
    "            for day in DAY_RANGE:\n",
    "                if day > forecast_horizon:\n",
    "                    print(f'{prefix}: skipping {day} (beyond 14-day forecast window).')\n",
    "                    continue\n",
    "\n",
    "                output_path = location_dir / f'{day.isoformat()}.csv'\n",
    "                if day != today and output_path.exists():\n",
    "                    print(f'{prefix}: skipping {day} (already exported).')\n",
    "                    continue\n",
    "\n",
    "                if day < today:\n",
    "                    historical_days.append(day)\n",
    "                    historical_requests.append({\n",
    "                        'location': (lat, lon),\n",
    "                        'date': day,\n",
    "                        'aqi': 'yes',\n",
    "                    })\n",
    "                else:\n",
    "                    forecast_days.append(day)\n",
    "                    forecast_requests.append({\n",
    "                        'location': (lat, lon),\n",
    "                        'days': 1,\n",
    "                        'start_date': day,\n",
    "                        'end_date': day,\n",
    "                        'aqi': 'yes',\n",
    "                        'alerts': 'yes',\n",
    "                    })\n",
    "\n",
    "            historical_payloads = weatherapi_client.get_historical_batch(historical_requests)\n",
    "            forecast_payloads = weatherapi_client.get_forecast_batch(forecast_requests)\n",
    "\n",
    "            _write_weatherapi_results(location_dir, prefix, historical_days, historical_payloads)\n",
    "            _write_weatherapi_results(location_dir, prefix, forecast_days, forecast_payloads)\n",
    "    except Exception as exc:\n",
    "        print(f\"WeatherAPI.com: unexpected error: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acdb295",
   "metadata": {},
   "source": [
    "## Data Caching Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "PROVIDER_LABELS = {\n",
    "    'tomorrow_io': 'Tomorrow.io',\n",
    "    'open_meteo': 'Open-Meteo',\n",
    "    'visual_crossing': 'Visual Crossing',\n",
    "    'noaa_isd': 'NOAA ISD',\n",
    "    'noaa_lcd': 'NOAA LCD',\n",
    "    'meteostat': 'Meteostat',\n",
    "    'nasa_power': 'NASA POWER',\n",
    "    'iem_asos': 'IEM ASOS',\n",
    "    'copernicus_era5_single': 'Copernicus ERA5 (single)',\n",
    "    'copernicus_era5_land': 'Copernicus ERA5-Land',\n",
    "    'copernicus_era5_pressure': 'Copernicus ERA5 (pressure)',\n",
    "    'copernicus_era5_land_timeseries': 'Copernicus ERA5-Land TS',\n",
    "    'openweather': 'OpenWeather',\n",
    "    'weatherbit': 'Weatherbit',\n",
    "    'weatherapi_com': 'WeatherAPI.com',\n",
    "}\n",
    "PROVIDER_RESOLUTION = {\n",
    "    'tomorrow_io': 'No cached data yet (expected 5m/1h timeline)',\n",
    "    'open_meteo': 'Hourly cadence (1h)',\n",
    "    'visual_crossing': 'Hourly cadence (1h)',\n",
    "    'noaa_isd': 'Sub-hourly METAR (median ~53 min)',\n",
    "    'noaa_lcd': 'Sub-hourly LCD (median ~53 min)',\n",
    "    'meteostat': 'Hourly multi-source blend (1h)',\n",
    "    'nasa_power': 'Hourly NASA POWER (satellite/model)',\n",
    "    'iem_asos': '1-min ASOS observations',\n",
    "    'copernicus_era5_single': 'Hourly ERA5 single levels',\n",
    "    'copernicus_era5_land': 'Hourly ERA5-Land (0.1 deg)',\n",
    "    'copernicus_era5_pressure': 'Hourly ERA5 pressure levels (0.25 deg)',\n",
    "    'copernicus_era5_land_timeseries': 'Hourly ERA5-Land point series',\n",
    "    'openweather': 'Hourly observations (1h)',\n",
    "    'weatherbit': 'No cached data yet',\n",
    "    'weatherapi_com': 'Hourly forecast/history (1h)',\n",
    "}\n",
    "provider_flags = [\n",
    "    ('tomorrow_io', USE_TOMORROW_IO),\n",
    "    ('open_meteo', USE_OPEN_METEO),\n",
    "    ('visual_crossing', USE_VISUAL_CROSSING),\n",
    "    ('noaa_isd', USE_NOAA_ISD),\n",
    "    ('noaa_lcd', USE_NOAA_LCD),\n",
    "    ('meteostat', USE_METEOSTAT),\n",
    "    ('nasa_power', USE_NASA_POWER),\n",
    "    ('iem_asos', USE_IEM_ASOS),\n",
    "    ('copernicus_era5_single', USE_COPERNICUS_ERA5_SINGLE),\n",
    "    ('copernicus_era5_land', USE_COPERNICUS_ERA5_LAND),\n",
    "    ('copernicus_era5_pressure', USE_COPERNICUS_ERA5_PRESSURE),\n",
    "    ('copernicus_era5_land_timeseries', USE_COPERNICUS_ERA5_LAND_TS),\n",
    "    ('openweather', USE_OPENWEATHER),\n",
    "    ('weatherbit', USE_WEATHERBIT),\n",
    "    ('weatherapi_com', USE_WEATHERAPI_COM),\n",
    "]\n",
    "date_index = pd.date_range(START_DATE, END_DATE, freq='D')\n",
    "active_providers = [key for key, enabled in provider_flags if enabled and key in PROVIDER_LABELS]\n",
    "if not active_providers:\n",
    "    print('No providers enabled; skipping cached coverage chart.')\n",
    "else:\n",
    "    cmap = ListedColormap(['#f0f0f0', '#2ca02c'])\n",
    "    fig, axes = plt.subplots(len(active_providers), 1, figsize=(16, 2.5 * len(active_providers)), sharex=True)\n",
    "    if len(active_providers) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, provider_key in zip(axes, active_providers):\n",
    "        provider_dir = DATA_ROOT / provider_key\n",
    "        coverage_rows = []\n",
    "        location_names = []\n",
    "        for location_name, *_coords in iter_locations():\n",
    "            location_dir = provider_dir / location_name\n",
    "            row = []\n",
    "            for day in date_index:\n",
    "                file_path = location_dir / f\"{day.date().isoformat()}.csv\"\n",
    "                row.append(file_path.exists())\n",
    "            coverage_rows.append(row)\n",
    "            location_names.append(location_name)\n",
    "        if not coverage_rows:\n",
    "            ax.text(0.5, 0.5, 'No location data available', ha='center', va='center')\n",
    "            ax.set_axis_off()\n",
    "            continue\n",
    "        data = np.array(coverage_rows, dtype=int)\n",
    "        im = ax.imshow(data, aspect='auto', interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
    "        ax.set_yticks(range(len(location_names)))\n",
    "        ax.set_yticklabels(location_names)\n",
    "        tick_count = min(len(date_index), 10)\n",
    "        if tick_count > 0:\n",
    "            tick_positions = np.linspace(0, len(date_index) - 1, tick_count, dtype=int)\n",
    "            ax.set_xticks(tick_positions)\n",
    "            ax.set_xticklabels([date_index[i].date().isoformat() for i in tick_positions], rotation=45, ha='right')\n",
    "        label = PROVIDER_LABELS.get(provider_key, provider_key)\n",
    "        resolution = PROVIDER_RESOLUTION.get(provider_key, '')\n",
    "        title_suffix = f\" ({resolution})\" if resolution else ''\n",
    "        ax.set_title(f\"{label}{title_suffix}\")\n",
    "        ax.set_ylabel('Location')\n",
    "    axes[-1].set_xlabel('Date')\n",
    "    fig.suptitle(f\"Cached coverage {START_DATE.isoformat()}  {END_DATE.isoformat()}\")\n",
    "    plt.tight_layout(rect=(0, 0, 1, 0.97))\n",
    "    cbar = fig.colorbar(im, ax=axes, orientation='horizontal', fraction=0.025, pad=0.08)\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.set_ticklabels(['Missing', 'Cached'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
